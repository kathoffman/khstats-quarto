{
  "hash": "50e84c9ce32aec959d6c34c50e6e8cb6",
  "result": {
    "markdown": "---\ntitle: \"Building Statistical Intuition for Individualized Treatment Rules\"\nauthor: \"Katherine Hoffman\"\ndate: \"2022-08-10\"\ncategories: [statistics]\nimage: \"image.png\"\ndescription: \" \"\n---\n\n```{=tex}\n\\usepackage{amsmath}\n\\DeclareMathOperator*{\\argmax}{arg\\,max}\n```\n\n\n\n\nDeveloping and optimizing **individualized treatment rules (ITRs)** is a fast-growing topic in the medical research community. A treatment rule is a **decision for treatment based upon a person's characteristics**. The intuition behind this is that not all individuals will respond to a treatment in the same way. We can exploit these **heterogeneous effects** and develop personalized rules which provide benefit a greater number of people.\n\nThe methods of ITRs are rooted in **principles of causal inference**, or using data to inform us about what would have happened in a hypothetical world in which different interventions had occurred. This post walks through the basic statistical intuition for ITRs. Each explanation is accompanied by mathematical notation and a small graphic to convey equivalent meaning.\n\n> Although this post is introductory, it assumes basic knowledge in causal inference, such as *counterfactual outcomes*, *assumptions for causal identification*, *Average Treatment Effect*, and [*G-computation*/*g-formula*](https://github.com/kathoffman/causal-inference-visual-guides/blob/master/visual-guides/G-Computation.pdf).\n\n# Table of Contents\n\n1.  üó∫Ô∏è [The big-picture approach to ITRs](#the-big-picture-of-itrs)\n\n2.  üìà [A simple estimation example](#estimating-the-itr)\n\n3.  üñ•Ô∏è [`R` code for a simple estimation example](#r-simulation)\n\n# üó∫Ô∏è The Big Picture of ITRs {#the-big-picture-of-itrs}\n\nIn this first section, we will translate the concept of developing and optimizing an ITR into mathematical notation.\n\n1.  We will start with a standard set-up: we have a matrix of observed data $O$ which includes our **outcome** $Y$, the **exposure** (i.e. treatment, medicine, etc.) we want to study $A$, and other **covariates** $\\textbf{W}$. Each row is an observation. We can denote these columns of data, which are random variables, as $O = (\\textbf{W}, A, Y)$.\n\n![](otr/data_structure.png){width=\"80%\"}\n\n<!-- , and visualize it as the following data set. *Note that we are considering a binary exposure for simplicity.* -->\n\n<!-- ![](tmle/1_data_structure.png){width=80%} -->\n\n2.  Now, consider we create some function, $d$, which takes baseline confounders $\\textbf{W}$ and outputs a treatment assignment $A$. We can write this mapping function, or **treatment rule**, in mathematical notation as:\n\n<!-- <p style=\"margin-left: 40px\"> -->\n\n\n$$d: \\textbf{W} \\rightarrow A$$ This is equivalent to a function you could write in R or Python which takes a matrix `W` and outputs a vector of treatment assignments `A`, which may or may not be the same treatment assignment as what each observation actually received.\n\n![](otr/input_output.png){width=\"80%\"}\n\n<!-- <p style=\"margin-left: 40px\">An example in `R` code could be this:</p>  -->\n\n<!-- <p style=\"margin-left: 40px\"> -->\n\n<!-- ```{r} -->\n\n<!-- d <- function(W){ -->\n\n<!--   # assigned treatment A is a vector of length nrow(W) and depends on values of W -->\n\n<!--   # for example, the treatment rule could be if W1 is greater than 5, treat, otherwise, don't treat -->\n\n<!--   A <- ifelse(W[[1]] > 5, 1, 0) -->\n\n<!--   return(A) -->\n\n<!-- } -->\n\n<!-- ``` -->\n\n<!-- </p>  -->\n\n3.  We can then think about the **counterfactual outcome**[^1] for each row, or observation, under the treatment rule $d$. In other words, we ask, \\*\"what would have happened in a hypothetical world where the treatment rule\\* $d$ was applied?\"\n\n[^1]: Recall that a counterfactual describes a hypothetical world where a unit received a certain intervention or treatment, which might be different from the treatment they actually received\n\nLet's denote this vector of counterfactual outcomes as $Y(d)$.\n\n![](otr/Y_d.png){width=\"100%\"}\n\n4.  The optimal ITR will **maximize the expected counterfactual outcome**, or $\\mathrm{E}[Y(d)]$, across the entire population. We can write that using $\\mathop{\\mathrm{arg\\,max}}$, which means we want to know which argument will return the highest value of a function. In this use-case, we want to know what treatment rule $d$ returns the highest expected value of the counterfactual outcome, $\\mathrm{E}[Y(d)]$.\n\n\n$$\\mathop{\\mathrm{arg\\,max}}_d \\mathrm{E}[Y(d)]$$\n\n\n![](otr/argmax.png){width=\"70%\"}\n\n5.  We can call whatever function $d$, or $d(\\textbf{W})$, that maximizes this expected counterfactual outcome for the population $d^*$. **This** $d^*$ is our optimal ITR.\n\n![](otr/d_star.png){width=\"50%\"}\n\n# üìà Estimating the ITR {#estimating-the-itr}\n\nThere are many ways to estimate $d^*$. One of the most common ways begins by estimating the **Conditional Average Treatment Effect (CATE)**.\n\nYou have probably heard of the Average Treatment Effect (ATE), which is the mean difference in outcomes in a world in which every unit receives the exposure compared to a world in which no unit receives the exposure. In potential outcomes notation, $ATE = \\mathrm{E}[Y^1-Y^0]$. The CATE is the same formula and description, but within covariate strata $W$.\n\n\n$$CATE = \\mathrm{E}[Y^1-Y^0|\\textbf{W}]$$\n\n\nUnder standard causal assumptions[^2], the CATE for a binary exposure is identifiable under the following formula:\n\n[^2]: This post is focused on estimation and therefore does not detail the requirements for causal identification, but here I refer to the assumptions of consistency, exchangeability, and positivity.\n\n$$\\mathrm{CATE}(W) = \\mathrm{E}[Y|A=1, \\textbf{W}] - \\mathrm{E}[Y|A=0, \\textbf{W}]$$ <!-- Compare this to the ATE after identification to clearly see the formula for CATE is the same, minus the outer expectation: -->\n\n\n<!-- $$\\mathrm{ATE}(W) = \\mathrm{E}[\\mathrm{E}[Y|A=1, W] - \\mathrm{E}[Y|A=0, W]]$$ -->\n\nWe could estimate the CATE using **G-computation**[^3]:\n\n[^3]: If you'd like a review on G-computation, check out this [**visual guide**](https://github.com/kathoffman/causal-inference-visual-guides/blob/master/visual-guides/G-Computation.pdf).\n\n1.  Fit a regression for $\\mathrm{E}[Y|A,\\textbf{W}]$.\n\n![](tmle/2_outcome_fit.png){width=\"70%\"}\n\n2.  Use the model fit from Step 1 to obtain predicted estimates for $Y$. Use two different datasets: one where all observations are changed to have $A=1$, and one where all observations are changed to have $A=0$.\n\n\n$$\\hat{E}[Y|A=1, \\textbf{W}]$$\n\n\n![](tmle/4_Q1.png){width=\"80%\"}\n\n\n$$\\hat{E}[Y|A=0, \\textbf{W}]$$\n\n\n![](tmle/5_Q1.png){width=\"80%\"}\n\n3.  Compute the difference of the quantities from Step 2.\n\n\n$$\\widehat{CATE} = \\hat{E}[Y|A=1, \\textbf{W}] - \\hat{E}[Y|A=0, \\textbf{W}]$$\n\n\n![](otr/cate.png){width=\"32%\"}\n\nNow, we could say our optimal ITR is to **give treatment if the value of** $CATE$ for that person is positive, indicating a positive effect of treatment on the outcome $Y$. Likewise, if the value is negative or 0, indicating a negative or neutral effect on the outcome $Y$, that unit would not receive treatment under the ITR.\n\n\\usepackage{bbm}\n\n\n$$ITR = \\mathbb{1}{ \\{CATE > 0} \\}$$\n\n\n![](otr/cate_assign_legend.png){width=\"50%\"}\n\n# üñ•Ô∏è `R` simulation {#r-simulation}\n\nLet's take a look an `R` simulation for the simple estimation of the $d^*$ we just described. We can first simulate data of `n` = 500 rows, where we have only one confounder `W`, a binary treatment `A` which depends on `W`, and an outcome `Y` which is continuous and depends on `W` and `A`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 500\nW <- runif(n, 1, 99)\nA <- rbinom(n, 1, prob = abs(W/100))\nY <- rnorm(n, 10) + rnorm(n, 2*A) + rnorm(n, 50*W) - rnorm(n, .1*A*W)\ndf <- data.frame(W, A, Y)\n```\n:::\n\n\nWe'll run a regression for a saturated linear regression model of $\\mathrm{E}[Y|A,\\textbf{W}]$, then obtain predictions on datasets where `A` is changed to `1` and `0` for all rows. We can then compute the CATE as the difference between these predictions.\n\n\n\n```{.r .cell-code}\nfit <- glm(Y~A*W)\nE_Y1 <- predict(fit, newdata = data.frame(A = 1, W))\nE_Y0 <- predict(fit, newdata = data.frame(A = 0, W))\nCATE <- E_Y1 - E_Y0\n```\n\n\nFinally, our optimal treatment rule will be to treat any unit with `CATE > 1`. If we plot the distribution of CATE in intervals of length 1, we can visually see there is benefit for about 1/4 of units in our simulated population.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata.frame(CATE) |>\n  mutate(d_star = ifelse(CATE > 0, \"Treat\", \"Do not treat\")) |>\n  ggplot(aes(CATE,fill=d_star)) +\n  geom_bar() +\n  scale_x_binned() +\n  theme_bw() +\n  scale_fill_manual(values = c(\"#f2696f\",\"#4984b0\")) +\n  labs(x=\"CATE\", y = \"Count\", fill = \"Treatment Rule\", title=\"Distribution of CATE\")\n```\n\n::: {.cell-output-display}\n![](otr_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n# Improving estimation of $d^*$\n\nThere are many other ways to estimate the $CATE$ with improved statistical properties, e.g. **double robustness**. We could also estimate $d^*$ directly instead of first estimating the $CATE$.\n\nWe can extend either of these ideas to longitudinal settings, studies with clustering, etc. I've listed some of the resources I've used to learn about optimizing ITRs below. As always, I welcome feedback and/or suggestions of additional resources I can include.\n\n------------------------------------------------------------------------\n\n# Further reading\n\nThese concepts are introductory, so any paper on \"optimal treatment rules\", \"individualized treatment rules\", or \"heterogeneous treatment effects\" should review the ideas discussed here in their introductions.\n\n-   This [Hoogland et al. tutorial](https://onlinelibrary.wiley.com/doi/10.1002/sim.9154) gives an introduction and code for ITRs.\n-   This [Wang et al. paper](https://www.bios.unc.edu/~dzeng/Pub/EHROLearning1.pdf) offers a clear mathematical introduction on ITRs.\n-   [Brady Neal's causal course Youtube series](https://www.youtube.com/watch?v=-0-RYxQ0zqM) (Chapter 6.2) discusses Conditional Outcome Modeling (what the CATE estimator falls under) over a 10 minute video.\n-   This [Angus and Chang *JAMA* Statistics and Research Methods paper](https://jamanetwork.com/journals/jama/fullarticle/2787131) gives an overview of a few ways to compute heterogeneous treatment effects for individualized treatment rules.\n-   Lately I've been interested in [this recent methods paper](https://arxiv.org/pdf/2004.14497.pdf) by Edward Kennedy. It discusses a way to evaluate the CATE using doubly robust estimation, and gives several other foundational papers in the introduction.\n-   [This `R` blog post](https://egap.org/resource/10-things-to-know-about-heterogeneous-treatment-effects/) about heterogeneous treatment effects also may be useful for thinking through these issues with real data.\n\nI'll continue to add resources to this list as I discover them. Please reach out if you have recommendations of papers or tutorials (yours or others!) to add to this list.\n\n------------------------------------------------------------------------\n\n## Acknowledgments\n\nThanks to my colleague [Iv√°n D√≠az](https://twitter.com/ildiazm) for explaining individualized treatment rules to me in this way, and for reviewing this post.\n",
    "supporting": [
      "otr_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}